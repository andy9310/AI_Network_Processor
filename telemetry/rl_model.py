"""
RLæ¨¡å‹è¼‰å…¥å’Œæ¨ç†æ¨¡çµ„
åŸºæ–¼PPOè¨“ç·´çš„å¼·åŒ–å­¸ç¿’æ¨¡å‹
"""

import torch
import torch.nn as nn
import numpy as np
import json
import os
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import logging
import random

# Try to import stable_baselines3, but don't fail if not available
try:
    from stable_baselines3 import PPO
    from stable_baselines3.common.policies import ActorCriticPolicy
    STABLE_BASELINES3_AVAILABLE = True
except ImportError:
    STABLE_BASELINES3_AVAILABLE = False
    print("âš ï¸ stable_baselines3 not available. Using mock model only.")

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Only define these classes if stable_baselines3 is available
if STABLE_BASELINES3_AVAILABLE:
    class NetworkFeatureExtractor(nn.Module):
        """ç¶²è·¯ç‰¹å¾µæå–å™¨ï¼Œèˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´"""
        def __init__(self, observation_space, features_dim=256):
            super().__init__()
            # Input shape: (n_links, 7)
            n_links = observation_space.shape[0]
            feature_dim = observation_space.shape[1]
            self.features_dim = features_dim
            
            # Process each link with a small network first
            self.link_encoder = nn.Sequential(
                nn.Linear(feature_dim, 32),
                nn.ReLU(),
                nn.Linear(32, 32),
                nn.ReLU()
            )
            
            # Simple attention mechanism (no LSTM)
            self.attention = nn.Sequential(
                nn.Linear(32, 1),
                nn.Softmax(dim=1)
            )
            
            # Global network features
            self.global_net = nn.Sequential(
                nn.Linear(32, 128),
                nn.ReLU(),
                nn.Linear(128, features_dim)
            )
        
        def forward(self, observations):
            batch_size = observations.shape[0]
            n_links = observations.shape[1]
            
            # Reshape to process each link
            flat_obs = observations.view(-1, observations.shape[2])
            
            # Process each link
            link_features = self.link_encoder(flat_obs)
            link_features = link_features.view(batch_size, n_links, -1)
            
            # Apply attention (no LSTM)
            attention_weights = self.attention(link_features)
            weighted_features = link_features * attention_weights
            
            # Sum across links (weighted by attention)
            global_features = weighted_features.sum(dim=1)
            
            return self.global_net(global_features)

    class EnhancedNetworkPolicy(ActorCriticPolicy):
        """å¢å¼·çš„ç¶²è·¯ç­–ç•¥ï¼Œèˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´"""
        def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):
            super().__init__(
                observation_space,
                action_space,
                lr_schedule,
                *args,
                **kwargs,
                features_extractor_class=NetworkFeatureExtractor,
                features_extractor_kwargs=dict(features_dim=256),
            )
else:
    # Placeholder classes when stable_baselines3 is not available
    class NetworkFeatureExtractor:
        """Placeholder for NetworkFeatureExtractor when stable_baselines3 is not available"""
        pass
    
    class EnhancedNetworkPolicy:
        """Placeholder for EnhancedNetworkPolicy when stable_baselines3 is not available"""
        pass

class MockRLModel:
    """æ¨¡æ“¬RLæ¨¡å‹ï¼Œç”¨æ–¼æ¸¬è©¦éšæ®µ"""
    
    def __init__(self):
        self.links = [
            "S1-S2", "S1-S3", "S1-S4", "S1-S9",
            "S2-S1", "S2-S4", "S2-S9",
            "S3-S1", "S3-S4", "S3-S9",
            "S4-S1", "S4-S2", "S4-S3", "S4-S5", "S4-S6", "S4-S7",
            "S4-S8", "S4-S9", "S4-S10", "S4-S11", "S4-S15",
            "S5-S4", "S5-S9",
            "S6-S4", "S6-S15",
            "S7-S4", "S7-S9",
            "S8-S4", "S8-S9",
            "S9-S1", "S9-S2", "S9-S3", "S9-S4", "S9-S5",
            "S9-S7", "S9-S8", "S9-S10", "S9-S15",
            "S10-S4", "S10-S9", "S10-S12", "S10-S13",
            "S10-S14", "S10-S15", "S10-S16", "S10-S17",
            "S11-S4", "S11-S15",
            "S12-S10", "S12-S15",
            "S13-S10", "S13-S15",
            "S14-S10", "S14-S15",
            "S15-S4", "S15-S6", "S15-S9", "S15-S10", "S15-S11",
            "S15-S12", "S15-S13", "S15-S14", "S15-S16", "S15-S17",
            "S16-S10", "S16-S15",
            "S17-S10", "S17-S15",
        ]
        
        # å®šç¾©ä¸€äº›é è¨­çš„é—œé–‰ç­–ç•¥
        self.closing_strategies = [
            # ç­–ç•¥1: é—œé–‰ä½æµé‡é€£çµ
            ["S1-S9", "S2-S9", "S3-S9", "S5-S9", "S7-S9", "S8-S9"],
            # ç­–ç•¥2: é—œé–‰é‚Šç·£é€£çµ
            ["S1-S2", "S1-S3", "S16-S10", "S17-S10", "S11-S4", "S12-S10"],
            # ç­–ç•¥3: é—œé–‰å†—é¤˜é€£çµ
            ["S4-S5", "S4-S6", "S4-S7", "S4-S8", "S9-S7", "S9-S8"],
            # ç­–ç•¥4: é—œé–‰é«˜å»¶é²é€£çµ
            ["S1-S4", "S2-S4", "S3-S4", "S10-S4", "S11-S4"],
            # ç­–ç•¥5: éš¨æ©Ÿé¸æ“‡
            ["S1-S2", "S3-S4", "S5-S9", "S10-S12", "S15-S16"]
        ]
        
        logger.info("ğŸ¤– Mock RL Model initialized for testing")
    
    def predict(self, observation, deterministic=True):
        """æ¨¡æ“¬æ¨¡å‹é æ¸¬ï¼Œè¿”å›éš¨æ©Ÿçš„é–¾å€¼"""
        # ç”Ÿæˆéš¨æ©Ÿçš„3ç¶­å‹•ä½œ (é–¾å€¼)
        action = np.random.uniform(0.0, 1.0, 3)
        return action, None

class RLModelManager:
    """
    RLæ¨¡å‹ç®¡ç†å™¨
    è² è²¬è¼‰å…¥è¨“ç·´å¥½çš„PPOæ¨¡å‹ã€è™•ç†è¼¸å…¥æ•¸æ“šã€é€²è¡Œæ¨ç†
    """
    
    def __init__(self, model_path: str = None, device: str = "cpu", use_mock: bool = True):
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        self.model = None
        # Update this path to match your trained model filename
        self.model_path = model_path or "models/python_model_20250810_161530"  # Path to extracted model
        self.use_mock = use_mock  # ä½¿ç”¨æ¨¡æ“¬æ¨¡å‹é€²è¡Œæ¸¬è©¦
        
        # æ­·å²æ•¸æ“šç”¨æ–¼è¨ˆç®—è®ŠåŒ–ç‡
        self.buffer_history = {}
        self.util_history = {}
        self.history_length = 3
        
        # ç¶²è·¯æ‹“æ’²ä¿¡æ¯ - ä½¿ç”¨è¨“ç·´æ™‚çš„ç¢ºåˆ‡hardcoded links (é›™å‘çš„)
        # åŸºæ–¼è¨“ç·´æ™‚ä½¿ç”¨çš„hardcoded_linksç”Ÿæˆé›™å‘é€£çµ
        hardcoded_links = [
            (0, 1),  # S1-S2
            (0, 2),  # S1-S3
            (0, 3),  # S1-S4
            (0, 8),  # S1-S9
            (1, 3),  # S2-S4
            (1, 8),  # S2-S9
            (2, 3),  # S3-S4
            (2, 8),  # S3-S9
            (3, 4),  # S4-S5
            (3, 5),  # S4-S6
            (3, 6),  # S4-S7
            (3, 7),  # S4-S8
            (3, 8),  # S4-S9
            (3, 9),  # S4-S10
            (3, 10), # S4-S11
            (3, 14), # S4-S15
            (4, 8),  # S5-S9
            (5, 14), # S6-S15
            (6, 8),  # S7-S9
            (7, 8),  # S8-S9
            (8, 9),  # S9-S10
            (8, 14), # S9-S15
            (9, 14), # S10-S15
            (9, 15), # S10-S16
            (9, 16)  # S10-S17
        ]
        
        # å°‡hardcoded_linksè½‰æ›ç‚ºé›™å‘çš„linkåç¨± (ç¸½å…±50å€‹)
        self.links = []
        for u, v in hardcoded_links:
            # æ·»åŠ é›™å‘é€£çµ
            self.links.append(f"S{u+1}-S{v+1}")
            self.links.append(f"S{v+1}-S{u+1}")
        
        logger.info(f"ğŸ”§ Using exactly {len(self.links)} hardcoded training links")
        
        # ç¯€é»åº¦æ•¸è¨ˆç®—ï¼ˆéœæ…‹ç‰¹å¾µï¼‰
        self.node_degrees = self._calculate_node_degrees()
        
        # è¼‰å…¥æ¨¡å‹
        self.load_model()
        
    def _calculate_node_degrees(self):
        """è¨ˆç®—æ¯å€‹linkçš„ç¯€é»åº¦æ•¸"""
        import networkx as nx
        
        # å‰µå»ºç¶²è·¯åœ–
        graph = nx.Graph()
        for i, link in enumerate(self.links):
            u, v = link.split("-")
            graph.add_edge(u, v, link_idx=i)
        
        # è¨ˆç®—æ¯å€‹linkçš„å¹³å‡ç¯€é»åº¦æ•¸
        node_degrees = np.zeros(len(self.links))
        for i, link in enumerate(self.links):
            u, v = link.split("-")
            node_degrees[i] = (graph.degree[u] + graph.degree[v]) / 2.0
            
        return node_degrees
        
    def load_model(self):
        """è¼‰å…¥è¨“ç·´å¥½çš„PPOæ¨¡å‹æˆ–ä½¿ç”¨æ¨¡æ“¬æ¨¡å‹"""
        if self.use_mock:
            logger.info("ğŸ¤– Using Mock RL Model for testing")
            self.model = MockRLModel()
            return
        
        # Check if stable_baselines3 is available
        if not STABLE_BASELINES3_AVAILABLE:
            logger.warning("âš ï¸ stable_baselines3 not available. Using Mock RL Model.")
            self.model = MockRLModel()
            return
        
        try:
            # Check if model directory exists (for extracted models) or zip file exists
            model_dir_exists = os.path.exists(self.model_path) and os.path.isdir(self.model_path)
            model_zip_exists = os.path.exists(self.model_path + ".zip")
            
            if model_dir_exists or model_zip_exists:
                logger.info(f"ğŸ”„ Loading RL model from {self.model_path}")
                
                # è¼‰å…¥PPOæ¨¡å‹
                self.model = PPO.load(
                    self.model_path,
                    device=self.device,
                    custom_objects={
                        "policy_class": EnhancedNetworkPolicy
                    }
                )
                
                logger.info("âœ… RL model loaded successfully")
                
            else:
                logger.warning(f"âš ï¸ Model file/directory not found: {self.model_path}")
                logger.info("ğŸ”„ Using Mock RL Model for testing...")
                self.model = MockRLModel()
                
        except Exception as e:
            logger.error(f"âŒ Failed to load RL model: {e}")
            logger.info("ğŸ”„ Falling back to Mock RL Model...")
            self.model = MockRLModel()
    
    def preprocess_telemetry_data(self, telemetry_data: Dict) -> np.ndarray:
        """
        é è™•ç†telemetryæ•¸æ“šï¼Œè½‰æ›ç‚ºæ¨¡å‹è¼¸å…¥æ ¼å¼
        èˆ‡è¨“ç·´æ™‚çš„_state()æ–¹æ³•ä¿æŒä¸€è‡´
        
        Args:
            telemetry_data: åŒ…å«linkæµé‡æ•¸æ“šçš„å­—å…¸
            
        Returns:
            np.ndarray: é è™•ç†å¾Œçš„è§€å¯Ÿç©ºé–“ (n_links, 7)
        """
        try:
            # ç¢ºä¿æˆ‘å€‘åªä½¿ç”¨é å®šç¾©çš„50å€‹link
            n_links = len(self.links)
            if n_links != 50:
                logger.error(f"âŒ Expected exactly 50 links, but have {n_links}")
                # å¼·åˆ¶è¨­å®šç‚º50å€‹link
                self.links = self.links[:50] if len(self.links) > 50 else self.links
                n_links = 50
            
            state = np.zeros((50, 7), dtype=np.float32)  # å¼·åˆ¶è¨­å®šç‚º(50, 7)
            
            # æª¢æŸ¥telemetry_dataçš„æ ¼å¼
            if not isinstance(telemetry_data, dict):
                logger.warning(f"âš ï¸ Expected dict for telemetry_data, got {type(telemetry_data)}")
                return state  # è¿”å›é›¶é™£åˆ—
            
            # èª¿è©¦ä¿¡æ¯
            logger.info(f"ğŸ”§ Processing {len(self.links)} predefined links, telemetry has {len(telemetry_data)} links")
            logger.info(f"ğŸ”§ State shape will be: {state.shape}")
            
            for i, link in enumerate(self.links):
                if link in telemetry_data:
                    current_data = telemetry_data[link]
                    
                    # æª¢æŸ¥current_dataæ˜¯å¦ç‚ºå­—å…¸æ ¼å¼
                    if not isinstance(current_data, dict):
                        # å¦‚æœcurrent_dataæ˜¯æ•¸å€¼ï¼Œå‡è¨­å®ƒæ˜¯trafficå€¼
                        if isinstance(current_data, (int, float)):
                            traffic = float(current_data)
                            output_drops = 0
                            output_queue_drops = 0
                            max_capacity = 1000  # é è¨­å€¼
                        else:
                            logger.warning(f"âš ï¸ Unexpected data format for {link}: {type(current_data)}")
                            continue
                    else:
                        # æ­£å¸¸çš„å­—å…¸æ ¼å¼
                        output_drops = current_data.get('output-drops', 0)
                        output_queue_drops = current_data.get('output-queue-drops', 0)
                        traffic = current_data.get('traffic', 0)
                        max_capacity = current_data.get('max-capacity', 1000)
                    
                    # è¨ˆç®—çµ±è¨ˆå€¼
                    total_drops = output_drops + output_queue_drops
                    link_utilization = min(1.0, traffic / max_capacity) if max_capacity > 0 else 0.0
                    
                    # ä¼°ç®—buffer utilization (åŸºæ–¼æ‰åŒ…ç‡)
                    drop_rate = total_drops / max(1, traffic + total_drops)
                    buffer_utilization = min(1.0, drop_rate * 10)
                    
                    # æ›´æ–°æ­·å²æ•¸æ“š
                    if link not in self.buffer_history:
                        self.buffer_history[link] = [buffer_utilization] * self.history_length
                    if link not in self.util_history:
                        self.util_history[link] = [link_utilization] * self.history_length
                    
                    self.buffer_history[link].append(buffer_utilization)
                    self.util_history[link].append(link_utilization)
                    
                    # ä¿æŒæ­·å²é•·åº¦
                    if len(self.buffer_history[link]) > self.history_length:
                        self.buffer_history[link] = self.buffer_history[link][-self.history_length:]
                    if len(self.util_history[link]) > self.history_length:
                        self.util_history[link] = self.util_history[link][-self.history_length:]
                    
                    # è¨ˆç®—è®ŠåŒ–ç‡
                    buffer_change = 0.0
                    util_change = 0.0
                    if len(self.buffer_history[link]) >= 2:
                        buffer_change = self.buffer_history[link][-1] - self.buffer_history[link][-2]
                    if len(self.util_history[link]) >= 2:
                        util_change = self.util_history[link][-1] - self.util_history[link][-2]
                    
                    # æ™‚é–“ç›¸é—œç‰¹å¾µï¼ˆç°¡åŒ–ï¼‰
                    time_since_change = 0.0  # ç°¡åŒ–è™•ç†
                    
                    # æ­£è¦åŒ–ç¯€é»åº¦æ•¸
                    max_degree = np.max(self.node_degrees) if len(self.node_degrees) > 0 else 1.0
                    norm_degree = self.node_degrees[i] / max_degree if max_degree > 0 else 0.0
                    
                    # çµ„è£ç‹€æ…‹å‘é‡ (èˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´)
                    state[i] = [
                        buffer_utilization,    # Buffer utilization
                        link_utilization,      # Link utilization
                        1.0,                   # Link status (å‡è¨­éƒ½æ˜¯up)
                        buffer_change,         # Buffer change rate
                        util_change,           # Utilization change rate
                        time_since_change,     # Time since last link state change
                        norm_degree,           # Normalized node degree
                    ]
            
            # ç¢ºä¿è¿”å›çš„stateå½¢ç‹€æ­£ç¢º
            if state.shape != (50, 7):
                logger.error(f"âŒ State shape mismatch! Expected (50, 7), got {state.shape}")
                state = np.zeros((50, 7), dtype=np.float32)
            
            logger.info(f"âœ… Returning state with shape: {state.shape}")
            return state
            
        except Exception as e:
            logger.error(f"âŒ Error preprocessing telemetry data: {e}")
            # è¿”å›é›¶é™£åˆ—ä½œç‚ºfallback - ç¢ºä¿æ˜¯(50, 7)
            return np.zeros((50, 7), dtype=np.float32)
    
    def predict_links_to_close(self, telemetry_data: Dict) -> List[str]:
        """
        ä½¿ç”¨RLæ¨¡å‹é æ¸¬é–¾å€¼ï¼Œç„¶å¾Œé€šésophisticated heuristicç®—æ³•æ±ºå®šé—œé–‰å“ªäº›link
        
        Args:
            telemetry_data: å³æ™‚æµé‡æ•¸æ“š
            
        Returns:
            List[str]: æ‡‰è©²é—œé–‰çš„linkåˆ—è¡¨
        """
        try:
            if self.model is None:
                logger.warning("âš ï¸ No RL model loaded, using fallback")
                return ["S1-S2", "S3-S4", "S5-S9"]
            
            # å¦‚æœæ˜¯æ¨¡æ“¬æ¨¡å‹ï¼Œä½¿ç”¨é å®šç¾©ç­–ç•¥
            if isinstance(self.model, MockRLModel):
                # éš¨æ©Ÿé¸æ“‡ä¸€å€‹ç­–ç•¥
                strategy = random.choice(self.model.closing_strategies)
                logger.info(f"ğŸ¤– Mock RL selected strategy: {strategy}")
                return strategy
            
            # é è™•ç†æ•¸æ“š
            observation = self.preprocess_telemetry_data(telemetry_data)
            
            # é€²è¡Œæ¨ç† - RLæ¨¡å‹é æ¸¬3å€‹é–¾å€¼
            action, _ = self.model.predict(observation, deterministic=True)
            
            # RLè¼¸å‡ºçš„actionå°±æ˜¯3å€‹é–¾å€¼ (bufLow, utilHi, utilCap)
            # é€™äº›é–¾å€¼æœƒè¢«heuristicç®—æ³•é€²ä¸€æ­¥è™•ç†å’Œç¸®æ”¾
            logger.info(f"ğŸ”§ RL raw thresholds: {action}")
            
            # ä½¿ç”¨sophisticated heuristicç®—æ³•é€²è¡Œæ±ºç­–
            if not hasattr(self, '_heuristic_manager'):
                from network_heuristic import NetworkHeuristicManager
                self._heuristic_manager = NetworkHeuristicManager()
            
            # é€šéheuristicç®—æ³•è™•ç†RLé æ¸¬çš„é–¾å€¼
            links_to_close = self._heuristic_manager.step(action, telemetry_data)
            
            logger.info(f"ğŸ¤– RL+Heuristic predicted {len(links_to_close)} links to close: {links_to_close}")
            return links_to_close
            
        except Exception as e:
            logger.error(f"âŒ Error in RL prediction: {e}")
            return ["S1-S2", "S3-S4", "S5-S9"]  # é è¨­å€¼
    
    def get_model_info(self) -> Dict:
        """ç²å–æ¨¡å‹ä¿¡æ¯"""
        if self.model is None:
            return {"status": "not_loaded"}
        
        model_type = "MockRLModel" if isinstance(self.model, MockRLModel) else "PPO"
        
        return {
            "status": "loaded",
            "model_path": self.model_path,
            "device": str(self.device),
            "model_type": model_type,
            "policy_type": "EnhancedNetworkPolicy" if model_type == "PPO" else "MockPolicy",
            "use_mock": self.use_mock
        }
    
    def save_model(self, save_path: str = None):
        """ä¿å­˜æ¨¡å‹"""
        if self.model is None:
            logger.error("âŒ No model to save")
            return
        
        save_path = save_path or self.model_path
        try:
            if not isinstance(self.model, MockRLModel) and STABLE_BASELINES3_AVAILABLE:
                self.model.save(save_path)
                logger.info(f"âœ… Model saved to {save_path}")
            else:
                logger.warning("âš ï¸ Cannot save MockRLModel or stable_baselines3 not available")
            
        except Exception as e:
            logger.error(f"âŒ Failed to save model: {e}")

# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å¯¦ä¾‹
rl_manager = None

def get_rl_manager(use_mock: bool = True) -> RLModelManager:
    """ç²å–å…¨å±€RLæ¨¡å‹ç®¡ç†å™¨å¯¦ä¾‹"""
    global rl_manager
    if rl_manager is None:
        rl_manager = RLModelManager(use_mock=use_mock)
    return rl_manager 