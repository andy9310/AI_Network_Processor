from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse
from pathlib import Path
import random, json, os, torch, textwrap
from unsloth import FastLanguageModel
from dotenv import load_dotenv
from collect import collect_link_traffic, fetch_generic_counters_legacy
from rl_model import get_rl_manager
from rag_system import get_rag_system
from restconf_processor import process_predicted_links
load_dotenv()
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¼‰å…¥LLMæ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MAX_SEQ_LEN  = 2048
MODEL_NAME   = "taide/Llama-3.1-TAIDE-LX-8B-Chat"
print("Loading modelâ€¦ (åªè¼‰ä¸€æ¬¡)")
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name     = MODEL_NAME,
    max_seq_length = MAX_SEQ_LEN,
    load_in_4bit   = True,                # ğŸ”§ 4-bit é‡åŒ–â†’ 8 GB VRAM å¤ ç”¨
    token          = os.getenv("HUGGINGFACE_TOKEN", ""),
)           
print("Model on", model.device)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¼‰å…¥RLæ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# åˆå§‹åŒ–RLæ¨¡å‹ç®¡ç†å™¨ (ä½¿ç”¨çœŸå¯¦è¨“ç·´å¥½çš„æ¨¡å‹)
rl_manager = get_rl_manager(use_mock=True)
print(f"ğŸ¤– RL Model Info: {rl_manager.get_model_info()}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¼‰å…¥RAGç³»çµ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# åˆå§‹åŒ–RAGç³»çµ± (ä½¿ç”¨å…è²»çš„æœ¬åœ°åµŒå…¥æ¨¡å‹)
try:
    rag_system = get_rag_system("all-MiniLM-L6-v2")
    print("ğŸ“š RAG System initialized with free local embeddings")

    # å˜—è©¦è¼‰å…¥Guide.docxæ–‡æª”
    try:
        rag_system.load_documents("Guide.docx")
        print("âœ… Guide.docx loaded into RAG system")
    except Exception as e:
        print(f"âš ï¸ Failed to load Guide.docx: {e}")
        print("ğŸ“ You can load documents later using the /load-document endpoint")
except Exception as e:
    print(f"âš ï¸ RAG System initialization failed: {e}")
    print("ğŸ“ RAG features will be disabled")
    rag_system = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â¸ System prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RULES_PATH = Path("rules.txt")
rules_text = RULES_PATH.read_text(encoding="utf-8")
SYSTEM_PROMPT = textwrap.dedent(f"""{rules_text.strip()}
ä½ æ˜¯ Cisco IOS XR ç¶²ç®¡åŠ©æ‰‹ï¼Œå®Œæ•´è¼¸å‡ºè¦é—œé–‰é€£çµå°æ‡‰ interface çš„ RESTCONF curl æŒ‡ä»¤èˆ‡å°æ‡‰ config JSON""")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â¹ Telemetry ç”¢ç”Ÿå™¨ (ç•¥)â€¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LINKS â€¦ generate_random_traffic() èˆ‡ collector() å®Œå…¨ç…§èˆŠ
# (æ­¤è™•çœç•¥ï¼Œä¿æŒåŸä¾†å‡½å¼ä¸è®Š)
LINKS = [
    "S1-S2", "S1-S3", "S1-S4", "S1-S9",
    "S2-S1", "S2-S4", "S2-S9",
    "S3-S1", "S3-S4", "S3-S9",
    "S4-S1", "S4-S2", "S4-S3", "S4-S5", "S4-S6", "S4-S7",
    "S4-S8", "S4-S9", "S4-S10", "S4-S11", "S4-S15",
    "S5-S4", "S5-S9",
    "S6-S4", "S6-S15",
    "S7-S4", "S7-S9",
    "S8-S4", "S8-S9",
    "S9-S1", "S9-S2", "S9-S3", "S9-S4", "S9-S5",
    "S9-S7", "S9-S8", "S9-S10", "S9-S15",
    "S10-S4", "S10-S9", "S10-S12", "S10-S13",
    "S10-S14", "S10-S15", "S10-S16", "S10-S17",
    "S11-S4", "S11-S15",
    "S12-S10", "S12-S15",
    "S13-S10", "S13-S15",
    "S14-S10", "S14-S15",
    "S15-S4", "S15-S6", "S15-S9", "S15-S10", "S15-S11",
    "S15-S12", "S15-S13", "S15-S14", "S15-S16", "S15-S17",
    "S16-S10", "S16-S15",
    "S17-S10", "S17-S15",
]

def generate_random_traffic(links=LINKS, min_traffic=1, max_traffic=1_000):
    traffic = {}
    for link in links:
        src, dst = link.split("-")
        fwd_key, rev_key = f"{src}-{dst}", f"{dst}-{src}"
        if fwd_key not in traffic:
            traffic[fwd_key] = random.randint(min_traffic, max_traffic)
        if rev_key not in traffic:
            traffic[rev_key] = random.randint(min_traffic, max_traffic)
    return traffic
def default_collector():
    """default Telemetry ç”¢ç”Ÿå™¨ã€‚"""
    return generate_random_traffic()

def collector():
    """å®Œæ•´ Telemetry ç”¢ç”Ÿå™¨ã€‚"""
    return collect_link_traffic(LINKS)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âº RLæ¨¡å‹é æ¸¬å‡½æ•¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_links_to_close_rl(telemetry_data: dict) -> list:
    """
    ä½¿ç”¨RLæ¨¡å‹é æ¸¬æ‡‰è©²é—œé–‰å“ªäº›link
    
    Args:
        telemetry_data: å³æ™‚æµé‡æ•¸æ“š
        
    Returns:
        list: æ‡‰è©²é—œé–‰çš„linkåˆ—è¡¨
    """
    try:
        return rl_manager.predict_links_to_close(telemetry_data)
    except Exception as e:
        print(f"âŒ Error in RL prediction: {e}")
        return ["L1", "L3", "L6"]  # é è¨­å€¼

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â» LLM æ¨è«– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def llm_inference(user_prompt: str = None, use_rag: bool = True):
    """
    LLM inference with optional RAG enhancement
    
    Args:
        user_prompt: Custom user prompt (optional)
        use_rag: Whether to use RAG enhancement (default: True)
    """
    telemetry_data = collector() ## link utilization
    links_to_close = predict_links_to_close_rl(telemetry_data)
    print(f"ğŸ¤– RL predicted links to close: {links_to_close}")
    
    # Process predicted links into RESTCONF commands
    commands, configs, commands_file, config_files = process_predicted_links(links_to_close)
    print(f"ğŸ“ RESTCONF commands saved to: {commands_file}")
    ## 
    telemetry_json = json.dumps(telemetry_data, ensure_ascii=False)
    
    # Use custom prompt or default
    if user_prompt:
        prompt = user_prompt
    else:
        prompt = f"è«‹æ ¹æ“šä¸Šè¿°è³‡æ–™ï¼Œé—œé–‰ {', '.join(links_to_close)}"
    
    # Enhance prompt with RAG if enabled
    if use_rag and rag_system is not None:
        try:
            enhanced_prompt = rag_system.enhance_prompt(prompt, SYSTEM_PROMPT)
            print(f"ğŸ“š RAG enhanced prompt with relevant documents")
        except Exception as e:
            print(f"âš ï¸ RAG enhancement failed: {e}")
            enhanced_prompt = prompt
            print(f"ğŸ“ Using original prompt without RAG")
    else:
        enhanced_prompt = prompt
        print(f"ğŸ“ Using original prompt without RAG")

    full_prompt = (
        f"ä»¥ä¸‹æ˜¯å³æ™‚æµé‡è³‡æ–™ï¼ˆJSONï¼‰ï¼š\n{telemetry_json}\n\n"
        f"{enhanced_prompt}"
    )

    chat = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user",   "content": full_prompt},
    ]

    input_ids = tokenizer.apply_chat_template(
        chat,
        tokenize=True,
        add_generation_prompt=True,
        return_tensors="pt",
    ).to("cuda")                           # ğŸ”§ å¼µé‡ä¹Ÿæ¬åˆ° GPU

    with torch.no_grad():
        outputs = model.generate(
            input_ids       = input_ids,
            max_new_tokens  = 256,
            do_sample       = True,
            temperature     = 0.7,
            top_p           = 0.9,
        )

    generated = outputs[0, input_ids.shape[-1]:]
    return tokenizer.decode(generated, skip_special_tokens=True).strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â¼ FastAPI ç«¯é» (åŸæ¨£) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(
    title       = "XR Telemetry + LLM Demo",
    description = "ç”¢ç”ŸTelemetryï¼Œä¸¦ç”¨ UnsLoTH Llama-3.1 taide ç”¢ RESTCONF æŒ‡ä»¤",
    version     = "1.0.0",
)

@app.get("/telemetry")
async def get_telemetry():
    try:
        return default_collector()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
@app.get("/input")
async def get_input():
    try:
        return {"input": "input"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/input")
async def post_input(user_prompt: str = None, use_rag: bool = True):
    """Allow users to add custom prompts to the LLM with RAG enhancement"""
    try:
        result = llm_inference(user_prompt=user_prompt, use_rag=use_rag)
        
        telemetry_data = collector()
        links_to_close = predict_links_to_close_rl(telemetry_data)
        
        return {
            "user_prompt": user_prompt,
            "use_rag": use_rag,
            "telemetry_data": telemetry_data,
            "predicted_links_to_close": links_to_close,
            "result": result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
        
@app.get("/output")
async def get_output(use_rag: bool = True):
    try:
        result = llm_inference(use_rag=use_rag)
        return {"result": result, "use_rag": use_rag}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ–°å¢ç«¯é»ï¼šä½¿ç”¨RLæ¨¡å‹é æ¸¬è¦é—œé–‰çš„link
@app.get("/predict-links-rl")
async def predict_links_rl():
    """ä½¿ç”¨RLæ¨¡å‹ä¾†é æ¸¬æ‡‰è©²é—œé–‰å“ªäº›link"""
    try:
        telemetry_data = collector()
        links_to_close = predict_links_to_close_rl(telemetry_data)
        
        # Process predicted links into RESTCONF commands
        commands, configs, commands_file, config_files = process_predicted_links(links_to_close)
        
        return {
            "telemetry_data": telemetry_data,
            "predicted_links_to_close": links_to_close,
            "restconf_commands": commands,
            "commands_file": str(commands_file),
            "config_files": [str(f) for f in config_files],
            "model_info": rl_manager.get_model_info()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ–°å¢ç«¯é»ï¼šç²å–RLæ¨¡å‹ä¿¡æ¯
@app.get("/rl-model-info")
async def get_rl_model_info():
    """ç²å–RLæ¨¡å‹ä¿¡æ¯"""
    try:
        return rl_manager.get_model_info()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ–°å¢ç«¯é»ï¼šè¼‰å…¥æ–‡æª”åˆ°RAGç³»çµ±
@app.post("/load-document")
async def load_document(file_path: str, force_reload: bool = False):
    """è¼‰å…¥æ–‡æª”åˆ°RAGç³»çµ±"""
    try:
        rag_system.load_documents(file_path, force_reload=force_reload)
        return {
            "message": f"Document {file_path} loaded successfully",
            "document_info": rag_system.get_document_info()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ–°å¢ç«¯é»ï¼šç²å–RAGç³»çµ±ä¿¡æ¯
@app.get("/rag-info")
async def get_rag_info():
    """ç²å–RAGç³»çµ±ä¿¡æ¯"""
    try:
        return rag_system.get_document_info()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ–°å¢ç«¯é»ï¼šæœç´¢ç›¸é—œæ–‡æª”
@app.get("/search-documents")
async def search_documents(query: str, top_k: int = 3):
    """æœç´¢ç›¸é—œæ–‡æª”"""
    try:
        results = rag_system.retrieve_relevant_docs(query, top_k=top_k)
        return {
            "query": query,
            "results": results,
            "total_found": len(results)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ–°å¢ç«¯é»ï¼šä¸‹è¼‰RESTCONFå‘½ä»¤æ–‡ä»¶
@app.get("/download-commands")
async def download_commands(filename: str = None):
    """ä¸‹è¼‰ç”Ÿæˆçš„RESTCONFå‘½ä»¤æ–‡ä»¶"""
    try:
        output_dir = Path("restconf_output")
        
        if filename:
            # Download specific file
            file_path = output_dir / filename
            if not file_path.exists():
                raise HTTPException(status_code=404, detail=f"File {filename} not found")
        else:
            # Download the most recent commands file
            command_files = list(output_dir.glob("restconf_commands_*.txt"))
            if not command_files:
                raise HTTPException(status_code=404, detail="No command files found")
            
            # Get the most recent file
            file_path = max(command_files, key=lambda f: f.stat().st_mtime)
        
        return FileResponse(
            path=str(file_path),
            filename=file_path.name,
            media_type="text/plain"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ–°å¢ç«¯é»ï¼šåˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å‘½ä»¤æ–‡ä»¶
@app.get("/list-command-files")
async def list_command_files():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„RESTCONFå‘½ä»¤æ–‡ä»¶"""
    try:
        output_dir = Path("restconf_output")
        
        if not output_dir.exists():
            return {"files": [], "message": "No output directory found"}
        
        # Get all command files
        command_files = list(output_dir.glob("restconf_commands_*.txt"))
        config_files = list(output_dir.glob("config_*.json"))
        
        file_info = []
        
        # Add command files info
        for file_path in command_files:
            stat = file_path.stat()
            file_info.append({
                "filename": file_path.name,
                "type": "commands",
                "size": stat.st_size,
                "created": stat.st_mtime,
                "download_url": f"/download-commands?filename={file_path.name}"
            })
        
        # Add config files info
        for file_path in config_files:
            stat = file_path.stat()
            file_info.append({
                "filename": file_path.name,
                "type": "config",
                "size": stat.st_size,
                "created": stat.st_mtime,
                "download_url": f"/download-config?filename={file_path.name}"
            })
        
        # Sort by creation time (newest first)
        file_info.sort(key=lambda x: x["created"], reverse=True)
        
        return {
            "files": file_info,
            "total_files": len(file_info),
            "command_files": len(command_files),
            "config_files": len(config_files)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# æ–°å¢ç«¯é»ï¼šä¸‹è¼‰é…ç½®æ–‡ä»¶
@app.get("/download-config")
async def download_config(filename: str):
    """ä¸‹è¼‰ç”Ÿæˆçš„JSONé…ç½®æ–‡ä»¶"""
    try:
        output_dir = Path("restconf_output")
        file_path = output_dir / filename
        
        if not file_path.exists():
            raise HTTPException(status_code=404, detail=f"Config file {filename} not found")
        
        return FileResponse(
            path=str(file_path),
            filename=file_path.name,
            media_type="application/json"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
