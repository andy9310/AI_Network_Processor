nohup: ignoring input
ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!
üöÄ Loading model‚Ä¶ (Âè™Ëºâ‰∏ÄÊ¨°)
Traceback (most recent call last):
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/taide/Llama-3.1-TAIDE-LX-8B-Chat

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/user/.local/share/mamba/envs/ai-llm/bin/uvicorn", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/click/core.py", line 1442, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/click/core.py", line 1363, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/click/core.py", line 1226, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/click/core.py", line 794, in invoke
    return callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/uvicorn/main.py", line 413, in main
    run(
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/uvicorn/main.py", line 580, in run
    server.run()
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/uvicorn/server.py", line 67, in run
    return asyncio.run(self.serve(sockets=sockets))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/uvicorn/server.py", line 71, in serve
    await self._serve(sockets)
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/uvicorn/server.py", line 78, in _serve
    config.load()
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/uvicorn/config.py", line 436, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/uvicorn/importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/mnt/c/Users/user/Desktop/AI-network/api-file/AI_Network_Processor/telemetry/main.py", line 11, in <module>
    model, tokenizer = FastLanguageModel.from_pretrained(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/unsloth/models/loader.py", line 207, in from_pretrained
    files = HfFileSystem(token = token).glob(f"{model_name}/*.json")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py", line 520, in glob
    path = self.resolve_path(path, revision=kwargs.get("revision")).unresolve()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py", line 209, in resolve_path
    repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py", line 125, in _repo_and_revision_exist
    self._api.repo_info(
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/hf_api.py", line 2844, in repo_info
    return method(
           ^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/hf_api.py", line 2629, in model_info
    hf_raise_for_status(r)
  File "/home/user/.local/share/mamba/envs/ai-llm/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 482, in hf_raise_for_status
    raise _format(HfHubHTTPError, str(e), response) from e
huggingface_hub.errors.HfHubHTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/taide/Llama-3.1-TAIDE-LX-8B-Chat (Request ID: Root=1-687cdbaa-43756dbe5202f0e269c895de;1edfade8-586e-432e-8e09-e5c0c24a585e)

Invalid credentials in Authorization header
